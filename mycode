import os
import json
import joblib
import random
import math
import gc
import warnings
from pathlib import Path

# Data Manipulation & Utility
import numpy as np 
import pandas as pd
import polars as pl
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from scipy.signal import butter, filtfilt

# PyTorch
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from torch.cuda.amp import autocast, GradScaler

# Kaggle Environment (keeping this for execution context)
try:
    import kaggle_evaluation.cmi_inference_server
except ImportError:
    print("Kaggle inference server not found. Running in standard environment.")
    class MockInferenceServer:
        def __init__(self, predictor): self.predictor = predictor
        def serve(self): pass
        def run_local_gateway(self, data_paths): print("Mock local gateway executed.")
    kaggle_evaluation = type('kaggle_evaluation', (object,), {'cmi_inference_server': type('cmi_inference_server', (object,), {'CMIInferenceServer': MockInferenceServer})})


warnings.filterwarnings("ignore")

# ================================
# ‚öôÔ∏è Configuration
# ================================
class Config:
    """Centralized configuration for the sensor data classification project."""
    # General Setup
    TRAIN_MODE = True
    RANDOM_SEED = 42
    # File Paths
    DATA_PATH = Path("../input/cmi-detect-behavior-with-sensor-data")
    PRETRAINED_MODEL_PATH = Path("/kaggle/input/cmi-models")
    OUTPUT_PATH = Path("./")
    # Training Parameters
    BATCH_SIZE = 96        # Batch size for training
    MAX_SEQUENCE_LENGTH = 100 # Time steps to pad/truncate sequences to
    LEARNING_RATE = 1.5e-3
    WEIGHT_DECAY = 5e-4    # L2 regularization
    MAX_EPOCHS = 100
    K_FOLDS = 5            # Number of folds for Stratified Cross-Validation
    EARLY_STOPPING_PATIENCE = 20
    LABEL_SMOOTHING_ALPHA = 0.15
    USE_MIXED_PRECISION = True

cfg = Config()
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Device: {device} | PyTorch: {torch.__version__}")

# Global variables (Initialized here for clarity)
sensor_models = []
data_normalizer = None
all_feature_columns = []
behavior_classes = []
imu_feature_cols = []
tof_feature_cols = []

# ================================
# üìê Utility Functions
# ================================
def set_global_seed(seed: int = cfg.RANDOM_SEED):
    """Sets seeds for reproducibility."""
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

def apply_lowpass_filter(data: np.ndarray, cutoff: float = 5, fs: float = 50, order: int = 4) -> np.ndarray:
    """Applies a Butterworth lowpass filter to time-series data."""
    if len(data) < 2 * order + 1: # Basic check to prevent filtfilt errors on short data
        return data
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    if normal_cutoff >= 1:
        return data # Cutoff too high, no filtering needed/possible
    b, a = butter(order, normal_cutoff, btype='low', analog=False)
    # Applying the filter only if data is long enough
    return filtfilt(b, a, data, axis=0)

def sequence_padding(seq: np.ndarray, maxlen: int, pad_value: float = 0.0) -> np.ndarray:
    """Pads or truncates a sequence to a fixed length (maxlen)."""
    current_len = len(seq)
    if current_len >= maxlen:
        return seq[:maxlen]
    else:
        # Pad at the end (bottom) of the sequence
        pad_width = ((0, maxlen - current_len), (0, 0))
        return np.pad(seq, pad_width, constant_values=pad_value)

# ================================
# ‚öôÔ∏è Feature Engineering Modules
# ================================
class IMUFeatureEngine(nn.Module):
    """
    Extracts basic features from IMU data (acceleration and rotation).
    Outputs include raw channels, magnitude, and a simple 1D convolution result.
    """
    def __init__(self, imu_feature_dim: int):
        super().__init__()
        self.imu_dim = imu_feature_dim
        # Convolution on 3 acceleration channels, grouped for efficiency
        self.accel_conv_3 = nn.Conv1d(in_channels=3, out_channels=12, 
                                      kernel_size=5, padding=2, groups=3)
        
    def forward(self, imu_input: torch.Tensor) -> torch.Tensor:
        """
        Args:
            imu_input: (B, C, T) tensor. C is imu_dim.
        Returns:
            (B, C_new, T) tensor with new features.
        """
        B, C, T = imu_input.shape
        
        # Split IMU into Acceleration (3 channels) and Rotation (C-3 channels)
        accel = imu_input[:, :3]
        rotation = imu_input[:, 3:] if C > 3 else torch.zeros(B, 1, T, device=imu_input.device)
        
        # Feature 1: Magnitude (L2 norm)
        accel_magnitude = torch.norm(accel, dim=1, keepdim=True)
        # Handle case where rotation might have 0 dimensions (C=3)
        rot_magnitude = torch.norm(rotation, dim=1, keepdim=True) if rotation.size(1) > 0 else torch.zeros(B, 1, T, device=imu_input.device)
        
        # Feature 2: Convolved Acceleration
        accel_conv_features = self.accel_conv_3(accel)
        
        # Concatenate raw channels and engineered features
        output_features = torch.cat([
            accel, rotation, 
            accel_magnitude, rot_magnitude, 
            accel_conv_features
        ], dim=1)
        
        return output_features

# ================================
# üß† Model Architecture Components
# ================================
class SeparableConvBlock(nn.Module):
    """
    Efficient Separable Convolution Block: Depthwise + Pointwise.
    Forms the core building block of the efficient network.
    """
    def __init__(self, in_ch: int, out_ch: int, kernel_size: int = 5, stride: int = 1, dropout_rate: float = 0.2):
        super().__init__()
        # 1. Depthwise Convolution
        self.depthwise_conv = nn.Conv1d(in_ch, in_ch, kernel_size, 
                                        stride=stride, padding=kernel_size//2, 
                                        groups=in_ch, bias=False)
        # 2. Pointwise Convolution (1x1)
        self.pointwise_conv = nn.Conv1d(in_ch, out_ch, 1, bias=False)
        self.batch_norm = nn.BatchNorm1d(out_ch)
        self.dropout = nn.Dropout(dropout_rate)
        self.activation = nn.SiLU(inplace=True)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.depthwise_conv(x)
        x = self.pointwise_conv(x)
        x = self.batch_norm(x)
        x = self.dropout(x)
        return self.activation(x)

class ChannelAttentionSE(nn.Module):
    """Squeeze-and-Excitation (SE) Block for Channel Attention."""
    def __init__(self, channels: int, reduction_ratio: int = 8):
        super().__init__()
        self.global_pool = nn.AdaptiveAvgPool1d(1)
        self.excitation_mlp = nn.Sequential(
            nn.Linear(channels, channels // reduction_ratio, bias=False),
            nn.SiLU(inplace=True),
            nn.Linear(channels // reduction_ratio, channels, bias=False),
            nn.Sigmoid()
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        b, c, _ = x.size()
        y = self.global_pool(x).view(b, c) # Squeeze operation
        y = self.excitation_mlp(y).view(b, c, 1) # Excitation operation
        return x * y.expand_as(x) # Scale the input

# ================================
# üß† Complete Model
# ================================
class SensorFusionClassifier(nn.Module):
    """
    A multi-modal CNN-Attention model for sensor data classification.
    It combines IMU (Inertial) and TOF (Distance) data streams.
    """
    def __init__(self, n_classes: int, imu_dim: int, tof_dim: int):
        super().__init__()
        self.imu_dim = imu_dim
        self.tof_dim = tof_dim
        
        # --- 1. IMU Feature Extraction ---
        self.imu_feature_engine = IMUFeatureEngine(imu_feature_dim=imu_dim)
        # Calculated feature dimension: 3 (acc) + (imu_dim-3) (rot) + 1 (acc_mag) + 1 (rot_mag) + 12 (conv)
        feat_out_dim = 3 + (imu_dim - 3) + 1 + 1 + 12 
        
        # --- 2. IMU CNN Pathway (Deeper, more regularization) ---
        self.imu_conv_1 = SeparableConvBlock(feat_out_dim, 96, kernel_size=7, dropout_rate=0.25)
        self.imu_pool_1 = nn.MaxPool1d(2)
        self.imu_se_1 = ChannelAttentionSE(96)
        
        self.imu_conv_2 = SeparableConvBlock(96, 192, kernel_size=5, dropout_rate=0.3)
        self.imu_pool_2 = nn.MaxPool1d(2)
        self.imu_se_2 = ChannelAttentionSE(192)
        
        # --- 3. TOF CNN Pathway (Simpler) ---
        self.tof_conv_1 = nn.Sequential(
            nn.Conv1d(tof_dim, 64, 3, padding=1, bias=False),
            nn.BatchNorm1d(64),
            nn.SiLU(inplace=True),
            nn.Dropout(0.25),
            nn.MaxPool1d(2)
        )
        self.tof_conv_2 = nn.Sequential(
            nn.Conv1d(64, 96, 3, padding=1, bias=False),
            nn.BatchNorm1d(96),
            nn.SiLU(inplace=True),
            nn.Dropout(0.3),
            nn.MaxPool1d(2)
        )
        
        # --- 4. Fusion and Temporal Attention ---
        fusion_dim = 192 + 96 # Output channels from x1 and x2
        self.temporal_attention = nn.MultiheadAttention(
            embed_dim=fusion_dim, num_heads=8, dropout=0.2, batch_first=True
        )
        
        # --- 5. Classification Head ---
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool1d(1), # Global Average Pooling over time
            nn.Flatten(),
            nn.Dropout(0.4),
            nn.Linear(fusion_dim, 192),
            nn.BatchNorm1d(192),
            nn.SiLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(192, n_classes)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: (B, T, C) input tensor containing all features.
        Returns:
            (B, n_classes) tensor of logits.
        """
        # (B, T, C) -> (B, C, T) and split
        imu = x[:, :, :self.imu_dim].transpose(1, 2)
        tof = x[:, :, self.imu_dim:].transpose(1, 2)
        
        # IMU stream
        imu_feat = self.imu_feature_engine(imu)
        x_imu = self.imu_conv_1(imu_feat)
        x_imu = self.imu_pool_1(x_imu)
        x_imu = self.imu_se_1(x_imu)
        
        x_imu = self.imu_conv_2(x_imu)
        x_imu = self.imu_pool_2(x_imu)
        x_imu = self.imu_se_2(x_imu)
        
        # TOF stream
        x_tof = self.tof_conv_1(tof)
        x_tof = self.tof_conv_2(x_tof)
        
        # Concatenate features: (B, C1+C2, T_new)
        x_fused = torch.cat([x_imu, x_tof], dim=1)
        
        # Temporal Attention (expects (B, T, C))
        x_attn_in = x_fused.transpose(1, 2)
        x_attn_out, _ = self.temporal_attention(x_attn_in, x_attn_in, x_attn_in)
        x_fused_attended = x_attn_out.transpose(1, 2) # (B, C, T)
        
        return self.classifier(x_fused_attended)

# ================================
# üìä Data Pipeline
# ================================
class SensorDataSequence(Dataset):
    """Custom Dataset for BFRB/CMI sensor sequences."""
    def __init__(self, sequences: np.ndarray, labels: np.ndarray, mode: str = 'train', imu_dim: int = 7):
        self.sequences = sequences
        self.labels = labels
        self.mode = mode
        self.imu_dim = imu_dim
        
    def __len__(self):
        return len(self.sequences)
        
    def __getitem__(self, idx: int):
        x = self.sequences[idx].copy()
        y = self.labels[idx]
        
        if self.mode == 'train':
            # --- Aggressive Data Augmentation for Robustness ---
            
            # 1. Gaussian Noise (primarily on IMU)
            if random.random() > 0.3:
                noise = np.random.randn(*x[:, :self.imu_dim].shape) * 0.02
                x[:, :self.imu_dim] += noise
                
            # 2. Random Scaling (primarily on IMU)
            if random.random() > 0.4:
                scale = np.random.uniform(0.9, 1.1)
                x[:, :self.imu_dim] *= scale
                
            # 3. Time Shift (Roll)
            if random.random() > 0.5:
                shift = np.random.randint(-5, 6)
                x = np.roll(x, shift, axis=0)
                
            # 4. Random Sensor Dropout (on TOF/other features)
            if random.random() > 0.6:
                # Apply scaling/dropout to all non-IMU features (TOF, THM)
                x[:, self.imu_dim:] *= np.random.uniform(0.0, 1.0) 
                
        return torch.FloatTensor(x), torch.LongTensor([y])[0]

def prepare_data_for_sequence(df_sequence: pd.DataFrame, feature_cols: list, normalizer=None, fit_normalizer: bool = False):
    """
    Applies filtering and normalization to a single sequence (DataFrame).
    """
    # 1. Fill NaN values (Use ffill, bfill, then 0 for any remaining)
    df_filled = df_sequence[feature_cols].select_dtypes(include=[np.number]).ffill().bfill().fillna(0)
    actual_feature_cols = df_filled.columns.tolist()
    
    # 2. Apply Low-Pass Filter to IMU data
    imu_cols_subset = [c for c in actual_feature_cols if c.startswith(('acc_', 'rot_'))]
    for col in imu_cols_subset:
        if col in df_filled.columns and len(df_filled) > 10:
            try:
                # Apply filter to the column's values
                df_filled[col] = apply_lowpass_filter(df_filled[[col]].values)
            except Exception:
                # Silently fail if filtering is not possible (e.g., short sequence)
                pass 

    # 3. Normalization (StandardScaler)
    if fit_normalizer:
        normalizer = StandardScaler()
        data_normalized = normalizer.fit_transform(df_filled.values)
    else:
        # Note: If normalizer is None here, it will raise an AttributeError which is intended 
        # to enforce fitting first.
        data_normalized = normalizer.transform(df_filled.values)
        
    return data_normalized.astype(np.float32), normalizer

# ================================
# üöÄ Training & Evaluation Functions
# ================================
def run_validation_epoch(model: nn.Module, loader: DataLoader, criterion: nn.Module, device: torch.device):
    """Evaluates the model on the validation set."""
    model.eval()
    val_loss = 0
    val_correct = 0
    val_total = 0
    
    with torch.no_grad():
        for batch_x, batch_y in loader:
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            
            val_loss += loss.item()
            _, predicted = outputs.max(1)
            val_total += batch_y.size(0)
            val_correct += predicted.eq(batch_y).sum().item()
            
    val_acc = 100. * val_correct / val_total
    return val_loss / len(loader), val_acc

def run_training_epoch(model: nn.Module, loader: DataLoader, optimizer: torch.optim.Optimizer, 
                       scheduler: torch.optim.lr_scheduler._LRScheduler, criterion: nn.Module, 
                       device: torch.device, use_amp: bool, scaler: GradScaler):
    """Runs a single training epoch with mixed precision support."""
    model.train()
    train_loss = 0
    train_correct = 0
    train_total = 0
    
    for batch_x, batch_y in loader:
        batch_x = batch_x.to(device)
        batch_y = batch_y.to(device)
        
        optimizer.zero_grad()
        
        if use_amp:
            with autocast():
                outputs = model(batch_x)
                loss = criterion(outputs, batch_y)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            
        scheduler.step()
        
        train_loss += loss.item()
        _, predicted = outputs.max(1)
        train_total += batch_y.size(0)
        train_correct += predicted.eq(batch_y).sum().item()
        
    train_acc = 100. * train_correct / train_total
    return train_loss / len(loader), train_acc

# ================================
# üíæ Main Training Logic
# ================================
def main_training_pipeline():
    """Executes the full K-Fold cross-validation training pipeline."""
    global data_normalizer, all_feature_columns, behavior_classes, imu_feature_cols, tof_feature_cols
    global sensor_models

    set_global_seed(cfg.RANDOM_SEED)
    print("Loading raw training data...")
    
    try:
        df_train = pd.read_csv(cfg.DATA_PATH / "train.csv")
    except FileNotFoundError:
        print(f"Error: train.csv not found at {cfg.DATA_PATH}. Aborting training.")
        return

    # 1. Label Encoding
    label_encoder = LabelEncoder()
    df_train['label'] = label_encoder.fit_transform(df_train['gesture'])
    behavior_classes = label_encoder.classes_
    np.save(cfg.OUTPUT_PATH / "behavior_classes.npy", behavior_classes)
    
    # 2. Feature Column Identification
    metadata_cols = {
        'gesture', 'label', 'sequence_type', 'behavior', 'orientation', 
        'row_id', 'subject', 'sequence_id', 'sequence_counter', 'phase'
    }
    all_feature_columns = [c for c in df_train.columns if c not in metadata_cols]
    # Filter to only numeric columns for safety
    all_feature_columns = df_train[all_feature_columns].select_dtypes(include=[np.number]).columns.tolist()

    # Separate IMU and TOF/THM columns
    imu_feature_cols = [c for c in all_feature_columns if not (c.startswith('thm_') or c.startswith('tof_'))]
    tof_feature_cols = [c for c in all_feature_columns if c.startswith(('thm_', 'tof_'))]
    all_feature_columns = imu_feature_cols + tof_feature_cols # Ensure correct order

    print(f"Features identified: {len(imu_feature_cols)} IMU + {len(tof_feature_cols)} TOF/THM = {len(all_feature_columns)} total")
    np.save(cfg.OUTPUT_PATH / "sensor_feature_cols.npy", all_feature_columns)
    
    # 3. Preprocessing Sequences (Normalization & Padding)
    print("Preprocessing, normalizing, and padding sequences...")
    sequences_array = []
    labels_array = []
    
    data_normalizer = None
    first_seq = True
    # Group by sequence_id to process one sequence at a time
    for _, group in df_train.groupby('sequence_id'):
        data_normalized, data_normalizer = prepare_data_for_sequence(
            group, all_feature_columns, data_normalizer, 
            fit_normalizer=first_seq # Fit the scaler only on the first sequence
        )
        sequences_array.append(sequence_padding(data_normalized, cfg.MAX_SEQUENCE_LENGTH))
        labels_array.append(group['label'].iloc[0]) # Label is constant per sequence
        first_seq = False
        
    joblib.dump(data_normalizer, cfg.OUTPUT_PATH / "data_normalizer.pkl")
    
    sequences_array = np.array(sequences_array)
    labels_array = np.array(labels_array)
    print(f"Final data shape for training: {sequences_array.shape}")
    
    # 4. K-Fold Cross-Validation Setup
    kfold_splitter = StratifiedKFold(n_splits=cfg.K_FOLDS, shuffle=True, random_state=cfg.RANDOM_SEED)
    
    for fold, (train_idx, val_idx) in enumerate(kfold_splitter.split(sequences_array, labels_array)):
        print(f"\n{'='*60}")
        print(f"STARTING FOLD {fold+1}/{cfg.K_FOLDS}")
        print(f"{'='*60}")
        
        # --- DataLoaders ---
        train_dataset = SensorDataSequence(
            sequences_array[train_idx], labels_array[train_idx], 
            mode='train', imu_dim=len(imu_feature_cols)
        )
        val_dataset = SensorDataSequence(
            sequences_array[val_idx], labels_array[val_idx], mode='val'
        )
        
        train_loader = DataLoader(
            train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True, 
            num_workers=2, pin_memory=True, drop_last=True
        )
        val_loader = DataLoader(
            val_dataset, batch_size=cfg.BATCH_SIZE * 2, shuffle=False, 
            num_workers=2, pin_memory=True
        )
        
        # --- Model, Optimizer, Loss, Scaler ---
        model = SensorFusionClassifier(
            n_classes=len(label_encoder.classes_),
            imu_dim=len(imu_feature_cols),
            tof_dim=len(tof_feature_cols)
        ).to(device)
        
        optimizer = AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)
        scheduler = torch.optim.lr_scheduler.OneCycleLR(
            optimizer, max_lr=cfg.LEARNING_RATE, epochs=cfg.MAX_EPOCHS,
            steps_per_epoch=len(train_loader),
            pct_start=0.15, anneal_strategy='cos'
        )
        
        criterion = nn.CrossEntropyLoss(label_smoothing=cfg.LABEL_SMOOTHING_ALPHA)
        scaler = GradScaler() if cfg.USE_MIXED_PRECISION else None
        
        # --- Training Loop ---
        best_val_acc = 0.0
        patience_counter = 0
        
        for epoch in range(cfg.MAX_EPOCHS):
            train_loss, train_acc = run_training_epoch(
                model, train_loader, optimizer, scheduler, criterion, device, 
                cfg.USE_MIXED_PRECISION, scaler
            )
            val_loss, val_acc = run_validation_epoch(model, val_loader, criterion, device)
            
            if (epoch + 1) % 10 == 0:
                print(f"Epoch {epoch+1:03d}/{cfg.MAX_EPOCHS} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | "
                      f"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%")
            
            # Early Stopping and Checkpointing
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                torch.save({
                    'model_state': model.state_dict(),
                    'imu_dim': len(imu_feature_cols),
                    'tof_dim': len(tof_feature_cols),
                    'n_classes': len(label_encoder.classes_)
                }, cfg.OUTPUT_PATH / f"sensor_model_fold{fold}.pth")
            else:
                patience_counter += 1
                if patience_counter >= cfg.EARLY_STOPPING_PATIENCE:
                    print(f"Early stopping triggered at epoch {epoch+1}")
                    break
                    
        print(f"Fold {fold+1} Finished. Best Validation Accuracy: {best_val_acc:.2f}%")
        
        # Load best model for ensemble
        checkpoint = torch.load(cfg.OUTPUT_PATH / f"sensor_model_fold{fold}.pth", map_location=device)
        best_model = SensorFusionClassifier(
            n_classes=checkpoint['n_classes'],
            imu_dim=checkpoint['imu_dim'],
            tof_dim=checkpoint['tof_dim']
        ).to(device)
        best_model.load_state_dict(checkpoint['model_state'])
        best_model.eval()
        sensor_models.append(best_model)
        
        # Cleanup
        del optimizer, scheduler, model
        gc.collect()
        torch.cuda.empty_cache()

    print(f"\n‚úì Training complete! {len(sensor_models)} ensemble models finalized.")

# ================================
# ‚öôÔ∏è Model Loading for Inference
# ================================
def load_for_inference():
    """Loads necessary artifacts and pretrained models for inference."""
    global data_normalizer, all_feature_columns, behavior_classes, imu_feature_cols, tof_feature_cols
    global sensor_models
    
    print("Loading pretrained artifacts for inference...")
    try:
        all_feature_columns = np.load(cfg.PRETRAINED_MODEL_PATH / "sensor_feature_cols.npy", allow_pickle=True).tolist()
        data_normalizer = joblib.load(cfg.PRETRAINED_MODEL_PATH / "data_normalizer.pkl")
        behavior_classes = np.load(cfg.PRETRAINED_MODEL_PATH / "behavior_classes.npy", allow_pickle=True)
    except FileNotFoundError:
        print("Error: Pretrained files not found. Cannot proceed with inference.")
        return False
        
    imu_feature_cols = [c for c in all_feature_columns if not (c.startswith('thm_') or c.startswith('tof_'))]
    tof_feature_cols = [c for c in all_feature_columns if c.startswith(('thm_', 'tof_'))]
    
    for fold in range(cfg.K_FOLDS):
        try:
            checkpoint = torch.load(cfg.PRETRAINED_MODEL_PATH / f"sensor_model_fold{fold}.pth", map_location=device)
            model = SensorFusionClassifier(
                n_classes=checkpoint['n_classes'],
                imu_dim=checkpoint['imu_dim'],
                tof_dim=checkpoint['tof_dim']
            ).to(device)
            model.load_state_dict(checkpoint['model_state'])
            model.eval()
            sensor_models.append(model)
        except FileNotFoundError:
            print(f"Warning: Model for fold {fold} not found. Skipping.")
            
    print(f"‚úì Loaded {len(sensor_models)} ensemble models.")
    return len(sensor_models) > 0


# ================================
# üöÄ Inference Entry Point
# ================================
def predict_sequence_gesture(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:
    """
    Main prediction function exposed to the Kaggle inference server.
    Performs ensemble prediction on a single sequence.
    """
    global sensor_models, data_normalizer, all_feature_columns, behavior_classes
    
    if not sensor_models:
        # Should be caught by the main logic, but for safety
        raise RuntimeError("No trained models are available for prediction.")
    
    # 1. Preprocess sequence
    df_pd = sequence.to_pandas()
    data_np, _ = prepare_data_for_sequence(df_pd, all_feature_columns, data_normalizer, fit_normalizer=False)
    data_padded = sequence_padding(data_np, cfg.MAX_SEQUENCE_LENGTH)
    
    # 2. Convert to PyTorch tensor
    x_input = torch.FloatTensor(data_padded).unsqueeze(0).to(device)
    
    # 3. Ensemble Prediction
    with torch.no_grad():
        all_probs = []
        for model in sensor_models:
            output = model(x_input)
            prob = F.softmax(output, dim=1)
            all_probs.append(prob)
            
        # Average the probabilities across all ensemble models (Soft Voting)
        avg_prob = torch.stack(all_probs).mean(0)
        pred_idx = avg_prob.argmax(1).item()
        
    # 4. Convert index back to class label
    return str(behavior_classes[pred_idx])

# ================================
# üèÅ Script Execution
# ================================
if cfg.TRAIN_MODE:
    main_training_pipeline()
else:
    load_for_inference()

print(f"\n{'='*60}")
print(f"INFERENCE SERVICE INITIALIZATION")
print(f"Models Count: {len(sensor_models)} | Feature Count: {len(all_feature_columns)} | Classes Count: {len(behavior_classes)}")
print(f"{'='*60}\n")

# Connect to Kaggle Interface
inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict_sequence_gesture)

if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):
    inference_server.serve()
else:
    # Local Test Gateway
    inference_server.run_local_gateway(
        data_paths=(
            cfg.DATA_PATH / 'test.csv',
            cfg.DATA_PATH / 'test_demographics.csv',
        )
    )
